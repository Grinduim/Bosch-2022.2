{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "continental-graph",
   "metadata": {},
   "source": [
    "# Webserver com Flask\n",
    "\n",
    "Nesse exercicio iremos implementar um simples webserver com suas funcionalidades e rotas básicas para recebermos requisições de clientes através da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "palestinian-round",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import logging\n",
    "import socket\n",
    "import threading\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from flask import Flask, request, render_template\n",
    "from gevent.pywsgi import WSGIServer\n",
    "import requests\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-politics",
   "metadata": {},
   "source": [
    "### Utilizando a biblioteca logging\n",
    "A biblioteca logging do python já vem com boas ferramentas para nos auxiliar a monitorar nosso servidor, uma de suas principais funcionalidade são os handlers, com ele nós podemos decedir o que vai ser feito com as mensagens de log, podemos simplesmente printar no terminal, salvar elas em um arquivo, enviar através de http para outro servidor, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "creative-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_level = logging.DEBUG\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Handler para printar as mensagens de log no terminal\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setLevel(log_level)\n",
    "stream_handler.setFormatter(formatter)\n",
    "\n",
    "# Handler para salvar as mensagens de log em um arquivo\n",
    "file_handler = logging.FileHandler(\"./webserver.log\")\n",
    "file_handler.setLevel(log_level)\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "# instancia do Logger que iremos utilizar para escrever as mensagens\n",
    "logger = logging.getLogger(\"webserver\")\n",
    "logger.addHandler(stream_handler)\n",
    "logger.addHandler(file_handler)\n",
    "logger.setLevel(log_level)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-louisiana",
   "metadata": {},
   "source": [
    "### Instanciando as principais ferramentas do nosso webserver\n",
    "* Instância do nosso webserver Flask\n",
    "* Instância do nosso modelo utilizando o opencv\n",
    "* váriavel __version__ que nos auxilia a monitorar o versionamento que está rodando no servidor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "likely-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "__version__ = \"0.0.1\"\n",
    "app = Flask(\"inference_webserver\")\n",
    "model = cv2.dnn.readNetFromTensorflow(\"./nose_tracker_best_loss.pb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-glenn",
   "metadata": {},
   "source": [
    "Um ponto importante é que iremos trabalhar com um webserver que pode vir a receber requisições em paralelo, contudo temos um único modelo que irá fazer a predição pra todas as requisições. Isso se torna um problema, pois o que ocorre quando no meio da chamada model.forward() executamos o model.setInput() vindo de uma requisição em paralela? Nosso modelo irá nos retornar respostas erradas, podendo ser a resposta de outro input ou até mesmo respostas aleatórias, ou seja, __nosso modelo não é thread safe__.\n",
    "\n",
    "Para resolver isso vamos utilizar uma instância do Lock disponibilizada pela biblioteca threading. Com o Lock nós conseguimos criar uma trava entre as requisições fazendo com que a requisição só consiga utilizar o modelo quando nenhuma outra requisição esteja utilizando.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "amino-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "lock = threading.Lock()\n",
    "binary_counter = 0\n",
    "base64_counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-murder",
   "metadata": {},
   "source": [
    "### Decorators\n",
    "Nosso servidor Flask utiliza decorators para criar e inserir as funcionalidades das rotas.\n",
    "Um decorator é um método que nos permite adcionar funcinalidades em uma função/objeto já existente.\n",
    "A idéia é semelhante a um callback, um decorator criar uma nova função e que dentro desse nova função determiandas tarefas serão executadas e em algum momento essa função criada irá executar o objeto/função de origem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-shopping",
   "metadata": {},
   "source": [
    "### Decorator para mensurar o tempo de execução da nossa rota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "above-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_it(func):\n",
    "    def decorator(*args, **kwargs):\n",
    "        started_time = time.time()\n",
    "        ret = func(*args, **kwargs)\n",
    "        logger.debug(f\"{time.time() - started_time:0.04f} took to be executed.\")\n",
    "        return ret\n",
    "    decorator.__name__ = func.__name__  # Para funcionar com o Flask\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-surgery",
   "metadata": {},
   "source": [
    "### Criação da nossa rota\n",
    "Nesse exemplo vamos criar uma rota que irá receber através de um \"POST\" um json contendo nossa imagem no formato base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hairy-monday",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@app.route(\"/image-64\", methods=['POST'])\n",
    "@time_it\n",
    "def image_b64():\n",
    "    print(type(request))\n",
    "    global base64_counter\n",
    "    base64_counter += 1\n",
    "    try:\n",
    "        json_dict = request.get_json()\n",
    "        json_dict = request.get_json()\n",
    "        logger.info(f\"Received keys: {json_dict.keys()}\")\n",
    "        if \"image\" not in json_dict:\n",
    "                raise RunTimeError(\"Expected to receive field image\")\n",
    "        image_array = base64.b64decode(json_dict[\"image\"])\n",
    "        image = cv2.imdecode(np.frombuffer(image_array, dtype=np.uint8), 1)\n",
    "        batch = cv2.resize(image, (112, 112))\n",
    "        batch = batch / 255\n",
    "        batch = batch[np.newaxis]\n",
    "        batch = np.transpose(batch, [0, 3, 1, 2])\n",
    "        with lock:\n",
    "            model.setInput(batch)\n",
    "            pred = model.forward()[0]\n",
    "        logger.info(f\"pred: {pred}\")\n",
    "        return json.dumps({\"x\": pred[0], \"y\": pred[1]}, indent=4, sort_keys=True, default=str), 200, {\"Content-Type\": \"application/json\"}\n",
    "    except Exception as e:\n",
    "        logger.error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "raised-blocking",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/image-bin\", methods=['POST'])\n",
    "@time_it\n",
    "def image_bin():\n",
    "    global binary_counter\n",
    "    binary_counter += 1\n",
    "    try:\n",
    "        image = cv2.imdecode(np.frombuffer(request.files[\"image\"].getvalue(), dtype=np.uint8), 1)\n",
    "        batch = cv2.resize(image, (112, 112))\n",
    "        batch = batch / 255\n",
    "        batch = batch[np.newaxis]\n",
    "        batch = np.transpose(batch, [0, 3, 1, 2])\n",
    "        with lock:\n",
    "            model.setInput(batch)\n",
    "            pred = model.forward()[0]\n",
    "        logger.info(f\"pred: {pred}\")\n",
    "        return json.dumps({\"x\": pred[0], \"y\": pred[1]}, indent=4, sort_keys=True, default=str), 200, {\"Content-Type\": \"application/json\"}\n",
    "    except Exception as e:\n",
    "        logger.error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vanilla-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/\")\n",
    "def dashboard():\n",
    "    try:\n",
    "        context = {\"base64\": base64_counter, \"binary\": binary_counter}\n",
    "        return render_template(\"./dashboard.html\", **context)\n",
    "    except Exception as e:\n",
    "        logger.error(e, exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-anderson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-covering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"inference_webserver\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "2021-04-15 14:04:12,177 - webserver - INFO - Received keys: dict_keys(['image'])\n",
      "2021-04-15 14:04:12,199 - webserver - INFO - pred: [0.6070819 0.5853746]\n",
      "2021-04-15 14:04:12,201 - webserver - DEBUG - 0.0419 took to be executed.\n",
      "127.0.0.1 - - [15/Apr/2021 14:04:12] \"\u001b[37mPOST /image-64 HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'werkzeug.local.LocalProxy'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-15 14:04:13,242 - webserver - INFO - Received keys: dict_keys(['image'])\n",
      "2021-04-15 14:04:13,251 - webserver - INFO - pred: [0.56466174 0.61133623]\n",
      "2021-04-15 14:04:13,253 - webserver - DEBUG - 0.0219 took to be executed.\n",
      "127.0.0.1 - - [15/Apr/2021 14:04:13] \"\u001b[37mPOST /image-64 HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'werkzeug.local.LocalProxy'>\n"
     ]
    }
   ],
   "source": [
    "LOCALHOST = True\n",
    "USE_GEVENT = False\n",
    "\n",
    "if LOCALHOST:\n",
    "    ip = \"127.0.0.1\"\n",
    "else:\n",
    "    ip = socket.gethostname()\n",
    "    \n",
    "if USE_GEVENT:\n",
    "    server = WSGIServer((ip, 5000), app)\n",
    "    server.serve_forever()\n",
    "else:\n",
    "    app.run(host=ip, port=5000, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-eleven",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
